# ai_librarian_cli_app.py
# ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô Command Line ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á AI Librarian V5.4
# ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏Å‡∏ô‡∏´‡∏•‡∏±‡∏Å (Core Logic) ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö app.py ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
# ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Backend ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (Imports) ---
import os
import json
import asyncio

# ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å LangChain ‡πÅ‡∏•‡∏∞ Google
from dotenv import load_dotenv
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser # ### <<< CHANGE: ‡πÄ‡∏û‡∏¥‡πà‡∏° JsonOutputParser >>> ###

# ### <<< CHANGE: ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏£‡∏≠‡∏°‡∏ï‡πå‡πÉ‡∏´‡∏°‡πà >>> ###
# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Dictionary `PROMPTS` ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏£‡∏≠‡∏°‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤
from prompts import AI_LANGUAGE_ROUTER_PROMPT, PROMPTS

# ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
import torch
import sounddevice as sd
import soundfile as sf
import edge_tts
from transformers import pipeline as hf_pipeline, AutoTokenizer, AutoModelForSpeechSeq2Seq, AutoFeatureExtractor

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° (Configurations) ---

load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY_NNG") # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ Key ‡∏ô‡∏µ‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå .env ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

if not GOOGLE_API_KEY:
    print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_API_KEY_NNG ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env")
    exit()

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á
WHISPER_MODEL_NAME = "openai/whisper-small"
VOICE_NAME_TH = "th-TH-NiwatNeural"
VOICE_NAME_EN = "en-US-GuyNeural"
AUDIO_FILE_INPUT = "user_input.wav"
AUDIO_FILE_OUTPUT = "ai_output.mp3"
SAMPLE_RATE = 16000
RECORD_DURATION = 7

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Chain (‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á AI) ---

db = None
llm_gemini_flash = None
language_router_chain = None
whisper_pipe = None
# ### <<< CHANGE: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö Chain ‡πÉ‡∏´‡∏°‡πà >>> ###
# ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ Dictionary ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö Chain ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤
chains = {
    "th": {},
    "en": {}
}

def load_models_and_chains():
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà AI ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
    ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô Initialization ‡πÉ‡∏ô app.py ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    """
    global db, llm_gemini_flash, language_router_chain, chains, whisper_pipe
    print("\n--- üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö AI Librarian (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô Command Line)... ---")

    try:
        # 1. ‡πÇ‡∏´‡∏•‡∏î Embedding Model ‡πÅ‡∏•‡∏∞ FAISS Index (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
        print("1. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Embedding Model ‡πÅ‡∏•‡∏∞ FAISS Index...")
        embeddings_model = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=GOOGLE_API_KEY)
        faiss_index_path = "faiss_index/book_index"
        if not os.path.exists(faiss_index_path):
            raise FileNotFoundError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå faiss_index/book_index ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô data_preparation.py ‡∏Å‡πà‡∏≠‡∏ô")
        db = FAISS.load_local(faiss_index_path, embeddings_model, allow_dangerous_deserialization=True)
        print("   ‚úÖ ‡∏Ñ‡∏•‡∏±‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

        # 2. ‡πÇ‡∏´‡∏•‡∏î LLM ‡∏´‡∏•‡∏±‡∏Å (Gemini 1.5 Flash)
        print("2. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î LLM ‡∏´‡∏•‡∏±‡∏Å (Gemini 1.5 Flash)...")
        llm_gemini_flash = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=GOOGLE_API_KEY, temperature=0.7)
        print("   ‚úÖ LLM ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Chain ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ
        print("3. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Chain ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô...")

        # ### <<< CHANGE: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Language Router >>> ###
        # Chain 3.1: ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤ (Language Router)
        # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ JsonOutputParser ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô Dictionary ‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        router_prompt = ChatPromptTemplate.from_template(AI_LANGUAGE_ROUTER_PROMPT)
        language_router_chain = router_prompt | llm_gemini_flash | JsonOutputParser()

        # ### <<< CHANGE: ‡∏™‡∏£‡πâ‡∏≤‡∏á Chain ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏ö‡∏ö‡πÑ‡∏î‡∏ô‡∏≤‡∏°‡∏¥‡∏Å >>> ###
        # Chain 3.2: ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏™‡∏£‡πâ‡∏≤‡∏á Chain ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡πÉ‡∏ô prompts.py
        for lang_code, lang_prompts in PROMPTS.items():
            print(f"   - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Chain ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤ '{lang_code.upper()}'...")
            
            # ‡∏ö‡∏£‡∏£‡∏ì‡∏≤‡∏£‡∏±‡∏Å‡∏©‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ (RAG Chain)
            rag_prompt = ChatPromptTemplate.from_messages([
                ("system", lang_prompts["RAG_LIBRARIAN"]),
                ("user", "Context:\n{context}\n\nQuestion:\n{question}")
            ])
            chains[lang_code]["rag"] = rag_prompt | llm_gemini_flash | StrOutputParser()

            # ‡∏ö‡∏£‡∏£‡∏ì‡∏≤‡∏£‡∏±‡∏Å‡∏©‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏•‡πà‡∏ô (General Chain)
            general_prompt = ChatPromptTemplate.from_messages([
                ("system", lang_prompts["GENERAL_LIBRARIAN"]),
                ("user", "{question}")
            ])
            chains[lang_code]["general"] = general_prompt | llm_gemini_flash | StrOutputParser()

        print("   ‚úÖ Chain ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

        # 4. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Whisper (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
        print(f"4. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Whisper Model ({WHISPER_MODEL_NAME})...")
        whisper_processor = AutoTokenizer.from_pretrained(WHISPER_MODEL_NAME)
        whisper_model = AutoModelForSpeechSeq2Seq.from_pretrained(WHISPER_MODEL_NAME)
        whisper_feature_extractor = AutoFeatureExtractor.from_pretrained(WHISPER_MODEL_NAME)
        whisper_pipe = hf_pipeline(
            "automatic-speech-recognition",
            model=whisper_model,
            tokenizer=whisper_processor,
            feature_extractor=whisper_feature_extractor,
            device=0 if torch.cuda.is_available() else -1,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        )
        print("   ‚úÖ Whisper Model ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        print("--- ‚ú® ‡∏£‡∏∞‡∏ö‡∏ö AI Librarian ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß! ---")

    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö: {e}")
        exit()

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ (Helpers) ---
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô record_audio, text_to_speech, play_audio, speech_to_text ‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏° ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
def record_audio(duration=RECORD_DURATION, samplerate=SAMPLE_RATE, filename=AUDIO_FILE_INPUT):
    print(f"\nüé§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á {duration} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ... ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö!")
    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='float32')
    sd.wait()
    sf.write(filename, recording, samplerate)
    print(f"   ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå '{filename}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
    return filename

async def text_to_speech(text, lang, filename=AUDIO_FILE_OUTPUT):
    print("   üîä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î...")
    voice_name = VOICE_NAME_TH if lang == "th" else VOICE_NAME_EN
    try:
        communicate = edge_tts.Communicate(text, voice_name)
        await communicate.save(filename)
        print(f"   ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á '{filename}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
        return filename
    except Exception as e:
        print(f"   ‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ: {e}")
        return None

def play_audio(filename=AUDIO_FILE_OUTPUT):
    if not filename or not os.path.exists(filename):
        print("   ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏•‡πà‡∏ô")
        return
    print("   ‚ñ∂Ô∏è  ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö...")
    try:
        if os.name == 'posix':
            os.system(f"afplay '{filename}'" if os.system("which afplay > /dev/null") == 0 else f"mpg123 -q '{filename}'")
        elif os.name == 'nt':
            os.system(f"start {filename}")
    except Exception as e:
        print(f"   ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")

async def speech_to_text(audio_file):
    print("   üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°...")
    try:
        result = whisper_pipe(audio_file)
        text = result["text"].strip()
        print(f"   ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤: '{text}'")
        return text
    except Exception as e:
        print(f"   ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
        return ""


# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å (Main Loop) ---

async def main():
    load_models_and_chains()
    print("\n=======================================================")
    print("      ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏™‡∏π‡πà AI Librarian (Command Line)")
    print("=======================================================")
    print("‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ '‡πÑ‡∏•‡∏ó‡πå' ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏£‡∏£‡∏ì‡∏≤‡∏£‡∏±‡∏Å‡∏©‡πå AI ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö")
    print("‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡∏´‡∏£‡∏∑‡∏≠ '0' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠")

    while True:
        print("\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏ú‡∏°‡∏Ñ‡∏£‡∏±‡∏ö:")
        print("  1: üìö ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ (RAG)")
        print("  2: üí¨ ‡πÇ‡∏´‡∏°‡∏î‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏•‡πà‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ")
        mode_choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î (1/2): ").strip()

        if mode_choice.lower() in ['exit', '0']: break
        if mode_choice == '1': selected_mode = 'rag'
        elif mode_choice == '2': selected_mode = 'general'
        else:
            print("   ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡∏ö"); continue

        print(f"\n--- üìö ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î: {selected_mode.upper()} ---")
        print("\n‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏£‡∏±‡∏ö:")
        print("  1: ‚å®Ô∏è ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
        print("  2: üéôÔ∏è  ‡∏û‡∏π‡∏î‡πÉ‡∏™‡πà‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô")
        input_choice = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ (1/2): ").strip()

        user_query = ""
        if input_choice == '1':
            user_query = input("\n‚úèÔ∏è  ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: ").strip()
        elif input_choice == '2':
            audio_file = record_audio()
            user_query = await speech_to_text(audio_file)
        else:
            print("   ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"); continue

        if not user_query:
            print("   ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡∏ö"); continue
        if user_query.lower() in ['exit', '0']: break

        print("\n" + "-"*20 + " ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• " + "-"*20)
        try:
            # ### <<< CHANGE: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô app.py >>> ###
            # 1. ‡πÉ‡∏ä‡πâ Language Router ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤
            print("1. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°...")
            router_result = language_router_chain.invoke({"question": user_query})
            detected_lang = router_result.get("language", "th")
            print(f"   ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ: {detected_lang.upper()}")

            # 2. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Chain ‡πÅ‡∏•‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î
            ai_response = ""
            source_documents = []

            # 2.1 ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Chain ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å Dictionary ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î
            selected_chain = chains[detected_lang][selected_mode]

            if selected_mode == 'rag':
                print("2. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (RAG)...")
                # 2.2 ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å FAISS ‡πÇ‡∏î‡∏¢ "‡∏Å‡∏£‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤" ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ
                docs = db.similarity_search(user_query, k=4, filter={"language": detected_lang})
                context = "\n\n".join([doc.page_content for doc in docs])
                source_documents = docs
                
                print("3. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö...")
                ai_response = selected_chain.invoke({"context": context, "question": user_query})
            else: # general
                print("2. ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (General Chat)...")
                ai_response = selected_chain.invoke({"question": user_query})

            # 3. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            print("\n--- üë®‚Äçüíª ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÑ‡∏•‡∏ó‡πå ---")
            print(ai_response)
            print("------------------------")

            audio_file = await text_to_speech(ai_response, detected_lang)
            play_audio(audio_file)

            if source_documents:
                print("\n--- üìö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å ---")
                unique_sources = set(doc.metadata.get('source', 'N/A') for doc in source_documents)
                for source in unique_sources:
                    print(f"  - {source}")

        except Exception as e:
            print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}")

        print("\n" + "="*50)

    print("\nüëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ AI Librarian ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà!")

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° ---
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\n‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ñ‡∏π‡∏Å‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ üëã")
